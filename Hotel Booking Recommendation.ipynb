{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5b22a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Ignore harmless warnings \n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set to display all the columns in dataset\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# Import psql to run queries \n",
    "\n",
    "import pandasql as psql \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a52f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the Social_Network_Ads dataset \n",
    "\n",
    "Hdata = pd.read_csv(r\"C:\\Users\\91772\\Downloads\\train.csv\", header=0)\n",
    "\n",
    "# Copy the file to back-up file\n",
    "\n",
    "Hdata_bk = Hdata.copy()\n",
    "\n",
    "# display first 5 records\n",
    "\n",
    "\n",
    "Hdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63649686",
   "metadata": {},
   "outputs": [],
   "source": [
    "Hdata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f264b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "del Hdata['user_id']\n",
    "del Hdata['is_mobile']\n",
    "del Hdata['site_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f3e2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "Hdata.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fe63a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the independent and Target (dependent) variables\n",
    "\n",
    "IndepVar = []\n",
    "for col in Hdata.columns:\n",
    "    if col != 'is_booking':\n",
    "        IndepVar.append(col)\n",
    "\n",
    "TargetVar = 'is_booking'\n",
    "\n",
    "x = Hdata[IndepVar]\n",
    "y = Hdata[TargetVar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9792e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test (random sampling)\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, stratify=y, random_state=42)\n",
    "x_test_F1 = x_test.copy()\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37504c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the features by using MinMaxScaler\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "mmscaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "x_train = mmscaler.fit_transform(x_train)\n",
    "x_train = pd.DataFrame(x_train)\n",
    "\n",
    "x_test = mmscaler.fit_transform(x_test)\n",
    "x_test = pd.DataFrame(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad01b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the result dataset\n",
    "\n",
    "EMResults = pd.read_csv(r\"C:\\Users\\91772\\Desktop\\aiml\\HTResults.csv\", header=0)\n",
    "EMResults.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0a2481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Calssification models and compare the results\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "#from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Create objects of classification algorithm with default hyper-parameters\n",
    "#ModelLin= LinearRegression()\n",
    "\n",
    "ModelLR = LogisticRegression()\n",
    "ModelDC = DecisionTreeClassifier()\n",
    "ModelRF = RandomForestClassifier()\n",
    "ModelET = ExtraTreesClassifier()\n",
    "ModelKNN = KNeighborsClassifier(n_neighbors=5)\n",
    "#ModelSVM = SVC(probability=True)\n",
    "\n",
    "modelBAG = BaggingClassifier(base_estimator=None, n_estimators=100, max_samples=1.0, max_features=1.0,\n",
    "                             bootstrap=True, bootstrap_features=False, oob_score=False, warm_start=False,\n",
    "                             n_jobs=None, random_state=None, verbose=0)\n",
    "\n",
    "ModelGB = GradientBoostingClassifier(loss='deviance', learning_rate=0.1, n_estimators=100, subsample=1.0, \n",
    "                                     criterion='friedman_mse', min_samples_split=2, min_samples_leaf=1, \n",
    "                                     min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_decrease=0.0,\n",
    "                                      init=None, random_state=None,\n",
    "                                     max_features=None, verbose=0, max_leaf_nodes=None, warm_start=False,\n",
    "                                     validation_fraction=0.1, n_iter_no_change=None, tol=0.0001, ccp_alpha=0.0)\n",
    "ModelLGB = lgb.LGBMClassifier()\n",
    "ModelGNB = GaussianNB()\n",
    "\n",
    "# Evalution matrix for all the algorithms\n",
    "\n",
    "MM = [ ModelLR, ModelDC, ModelRF, ModelET, ModelKNN,  modelBAG, ModelGB, ModelLGB, ModelGNB]\n",
    "for models in MM:\n",
    "    \n",
    "    # Fit the model\n",
    "    \n",
    "    models.fit(x_train, y_train)\n",
    "    \n",
    "    # Prediction\n",
    "    \n",
    "    y_pred = models.predict(x_test)\n",
    "    y_pred_prob = models.predict_proba(x_test)\n",
    "    \n",
    "    # Print the model name\n",
    "    \n",
    "    print('Model Name: ', models)\n",
    "    \n",
    "    # confusion matrix in sklearn\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    from sklearn.metrics import classification_report\n",
    "\n",
    "    # actual values\n",
    "\n",
    "    actual = y_test\n",
    "\n",
    "    # predicted values\n",
    "\n",
    "    predicted = y_pred\n",
    "\n",
    "    # confusion matrix\n",
    "\n",
    "    matrix = confusion_matrix(actual,predicted, labels=[1,0],sample_weight=None, normalize=None)\n",
    "    print('Confusion matrix : \\n', matrix)\n",
    "\n",
    "    # outcome values order in sklearn\n",
    "\n",
    "    tp, fn, fp, tn = confusion_matrix(actual,predicted,labels=[1,0]).reshape(-1)\n",
    "    print('Outcome values : \\n', tp, fn, fp, tn)\n",
    "\n",
    "    # classification report for precision, recall f1-score and accuracy\n",
    "\n",
    "    C_Report = classification_report(actual,predicted,labels=[1,0])\n",
    "\n",
    "    print('Classification report : \\n', C_Report)\n",
    "\n",
    "    # calculating the metrics\n",
    "\n",
    "    sensitivity = round(tp/(tp+fn), 3);\n",
    "    specificity = round(tn/(tn+fp), 3);\n",
    "    accuracy = round((tp+tn)/(tp+fp+tn+fn), 3);\n",
    "    balanced_accuracy = round((sensitivity+specificity)/2, 3);\n",
    "    \n",
    "    precision = round(tp/(tp+fp), 3);\n",
    "    f1Score = round((2*tp/(2*tp + fp + fn)), 3);\n",
    "\n",
    "    # Matthews Correlation Coefficient (MCC). Range of values of MCC lie between -1 to +1. \n",
    "    # A model with a score of +1 is a perfect model and -1 is a poor model\n",
    "\n",
    "    from math import sqrt\n",
    "\n",
    "    mx = (tp+fp) * (tp+fn) * (tn+fp) * (tn+fn)\n",
    "    MCC = round(((tp * tn) - (fp * fn)) / sqrt(mx), 3)\n",
    "\n",
    "    print('Accuracy :', round(accuracy*100, 2),'%')\n",
    "    print('Precision :', round(precision*100, 2),'%')\n",
    "    print('Recall :', round(sensitivity*100,2), '%')\n",
    "    print('F1 Score :', f1Score)\n",
    "    print('Specificity or True Negative Rate :', round(specificity*100,2), '%'  )\n",
    "    print('Balanced Accuracy :', round(balanced_accuracy*100, 2),'%')\n",
    "    print('MCC :', MCC)\n",
    "\n",
    "    # Area under ROC curve \n",
    "\n",
    "    from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "    print('roc_auc_score:', round(roc_auc_score(actual, predicted), 3))\n",
    "    \n",
    "    # ROC Curve\n",
    "    \n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    from sklearn.metrics import roc_curve\n",
    "    logit_roc_auc = roc_auc_score(actual, predicted)\n",
    "    fpr, tpr, thresholds = roc_curve(actual, models.predict_proba(x_test)[:,1])\n",
    "    plt.figure()\n",
    "    # plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "    plt.plot(fpr, tpr, label= 'Classification Model' % logit_roc_auc)\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig('Log_ROC')\n",
    "    plt.show()\n",
    "    print('-----------------------------------------------------------------------------------------------------')\n",
    "    #----------------------------------------------------------------------------------------------------------\n",
    "    new_row = {'Model Name' : models,\n",
    "               'True_Positive' : tp, \n",
    "               'False_Negative' : fn, \n",
    "               'False_Positive' : fp,\n",
    "               'True_Negative' : tn,\n",
    "               'Accuracy' : accuracy,\n",
    "               'Precision' : precision,\n",
    "               'Recall' : sensitivity,\n",
    "               'F1 Score' : f1Score,\n",
    "               'Specificity' : specificity,\n",
    "               'MCC':MCC,\n",
    "               'ROC_AUC_Score':roc_auc_score(actual, predicted),\n",
    "               'Balanced Accuracy':balanced_accuracy}\n",
    "    EMResults = EMResults.append(new_row, ignore_index=True)\n",
    "    #----------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7adf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results with comparing the all the algorithms \n",
    "\n",
    "#EMResults.to_csv(\"D://00 Henotic//SRKR//Datasets//Results//EMResults_22.csv\")\n",
    "\n",
    "EMResults.head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
